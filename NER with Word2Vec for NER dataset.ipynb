{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is dataset is available at https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus \n",
    "# You will also need spacy and the 'en_core_web_lg' or 'en_core_web_md' model isntalled.\n",
    "# the embedding_matrix function uses 'en_core_web_lg' by default, if you have 'en_core_web_md' instead change\n",
    "# nlp = spacy.load('en_core_web_lg') to nlp = spacy.load('en_core_web_md') in word2vec_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SentenceGetter import SentenceGetter\n",
    "from word2vec_functions import embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = os.path.join(os.getcwd(),\"ner_dataset.csv\")\n",
    "df= pd.read_csv(file, encoding=\"latin1\")\n",
    "df= df.fillna(method='ffill')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(df[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "\n",
    "tags = df['Tag'].unique().tolist()\n",
    "\n",
    "n_words = len(words)\n",
    "n_tags = len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences\n",
    "\n",
    "max_len = 50\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = os.path.join(os.getcwd(),'models','ner_dataset','word2vec_model2.h5')\n",
    "\n",
    "plateau_callback =ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=2)\n",
    "modelcheckpoint_callback = ModelCheckpoint(filepath=model_filename,monitor='val_accuracy',save_best_only=True)\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_embeddings = embedding_matrix(n_words,word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/anaconda3/envs/keras_book/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "network_1 = Embedding(input_dim=n_words + 1, \n",
    "                      output_dim=300,\n",
    "                      weights=[word2vec_embeddings],\n",
    "                      input_length=max_len,\n",
    "                      trainable=False)(input)\n",
    "network_1 = Dropout(0.2)(network_1)\n",
    "network_1 = Bidirectional(LSTM(units=300, return_sequences=True, recurrent_dropout=0.2))(network_1)\n",
    "#model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(network_1)  # softmax output layer\n",
    "\n",
    "model1 = Model(input, out)\n",
    "model1.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/anaconda3/envs/keras_book/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 26856 samples, validate on 11511 samples\n",
      "Epoch 1/30\n",
      "26856/26856 [==============================] - 209s 8ms/step - loss: 0.0979 - accuracy: 0.9731 - val_loss: 0.0627 - val_accuracy: 0.9811\n",
      "Epoch 2/30\n",
      "26856/26856 [==============================] - 203s 8ms/step - loss: 0.0598 - accuracy: 0.9814 - val_loss: 0.0562 - val_accuracy: 0.9822\n",
      "Epoch 3/30\n",
      "26856/26856 [==============================] - 202s 8ms/step - loss: 0.0510 - accuracy: 0.9837 - val_loss: 0.0522 - val_accuracy: 0.9836\n",
      "Epoch 4/30\n",
      "26856/26856 [==============================] - 203s 8ms/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.0504 - val_accuracy: 0.9843\n",
      "Epoch 5/30\n",
      "26856/26856 [==============================] - 205s 8ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0506 - val_accuracy: 0.9841\n",
      "Epoch 6/30\n",
      "26856/26856 [==============================] - 204s 8ms/step - loss: 0.0359 - accuracy: 0.9879 - val_loss: 0.0518 - val_accuracy: 0.9837\n",
      "Epoch 7/30\n",
      "26856/26856 [==============================] - 219s 8ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.0495 - val_accuracy: 0.9850\n",
      "Epoch 8/30\n",
      "26856/26856 [==============================] - 217s 8ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.0497 - val_accuracy: 0.9850\n",
      "Epoch 9/30\n",
      "26856/26856 [==============================] - 219s 8ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0502 - val_accuracy: 0.9849\n",
      "Epoch 10/30\n",
      "26856/26856 [==============================] - 216s 8ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0502 - val_accuracy: 0.9850\n",
      "Epoch 11/30\n",
      "26856/26856 [==============================] - 218s 8ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0502 - val_accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_train, np.array(y_train), \n",
    "                      batch_size=32, epochs=30, \n",
    "                      validation_split=0.3, verbose=1,\n",
    "                      callbacks=[plateau_callback,modelcheckpoint_callback,earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "network_2 = Embedding(input_dim=n_words + 1, \n",
    "                      output_dim=300,\n",
    "                      weights=[word2vec_embeddings],\n",
    "                      input_length=max_len,\n",
    "                      trainable=False)(input)\n",
    "network_2 = Dropout(0.2)(network_2)\n",
    "network_2 = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.2))(network_2)\n",
    "#model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(network_2)  # softmax output layer\n",
    "\n",
    "model2 = Model(input, out)\n",
    "model2.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34530 samples, validate on 3837 samples\n",
      "Epoch 1/30\n",
      "34530/34530 [==============================] - 71s 2ms/step - loss: 0.1022 - accuracy: 0.9729 - val_loss: 0.0662 - val_accuracy: 0.9802\n",
      "Epoch 2/30\n",
      "34530/34530 [==============================] - 72s 2ms/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.0571 - val_accuracy: 0.9825\n",
      "Epoch 3/30\n",
      "34530/34530 [==============================] - 70s 2ms/step - loss: 0.0547 - accuracy: 0.9828 - val_loss: 0.0540 - val_accuracy: 0.9832\n",
      "Epoch 4/30\n",
      "34530/34530 [==============================] - 69s 2ms/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0535 - val_accuracy: 0.9834\n",
      "Epoch 5/30\n",
      "34530/34530 [==============================] - 69s 2ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.0522 - val_accuracy: 0.9837\n",
      "Epoch 6/30\n",
      "34530/34530 [==============================] - 69s 2ms/step - loss: 0.0447 - accuracy: 0.9854 - val_loss: 0.0500 - val_accuracy: 0.9844\n",
      "Epoch 7/30\n",
      "34530/34530 [==============================] - 69s 2ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 0.0500 - val_accuracy: 0.9846\n",
      "Epoch 8/30\n",
      "34530/34530 [==============================] - 69s 2ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 0.0494 - val_accuracy: 0.9851\n",
      "Epoch 9/30\n",
      "34530/34530 [==============================] - 70s 2ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 0.0499 - val_accuracy: 0.9847\n",
      "Epoch 10/30\n",
      "34530/34530 [==============================] - 70s 2ms/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.0499 - val_accuracy: 0.9847\n",
      "Epoch 11/30\n",
      "34530/34530 [==============================] - 70s 2ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 0.0488 - val_accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, np.array(y_train), \n",
    "                      batch_size=32, epochs=30, \n",
    "                      validation_split=0.1, verbose=1,\n",
    "                      callbacks=[plateau_callback,modelcheckpoint_callback,earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592/9592 [==============================] - 22s 2ms/step\n",
      "9592/9592 [==============================] - 9s 937us/step\n"
     ]
    }
   ],
   "source": [
    "preds1 = model1.predict(np.array(X_test), verbose=1)\n",
    "preds2 = model2.predict(np.array(X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2label(y_matrix,idx2tag):\n",
    "    result = []\n",
    "    for y_vector1 in y_matrix:\n",
    "        output = []\n",
    "        for y_vector2 in y_vector1:\n",
    "            max_val = np.argmax(y_vector2)\n",
    "            output.append(idx2tag[max_val].replace(\"ENDPAD\", \"O\"))\n",
    "        result.append(output)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      org       1.00      1.00      1.00      3973\n",
      "      eve       1.00      1.00      1.00        48\n",
      "      tim       1.00      1.00      1.00      4018\n",
      "      art       1.00      1.00      1.00        21\n",
      "      gpe       1.00      1.00      1.00      3053\n",
      "      per       1.00      1.00      1.00      3439\n",
      "      nat       1.00      1.00      1.00        24\n",
      "      geo       1.00      1.00      1.00      7991\n",
      "\n",
      "micro avg       1.00      1.00      1.00     22567\n",
      "macro avg       1.00      1.00      1.00     22567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "pred_labels = convert2label(preds1,idx2tag)\n",
    "test_labels = convert2label(preds1,idx2tag)\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      org       1.00      1.00      1.00      3930\n",
      "      eve       1.00      1.00      1.00        41\n",
      "      tim       1.00      1.00      1.00      4024\n",
      "      art       1.00      1.00      1.00        14\n",
      "      gpe       1.00      1.00      1.00      3057\n",
      "      per       1.00      1.00      1.00      3432\n",
      "      nat       1.00      1.00      1.00        15\n",
      "      geo       1.00      1.00      1.00      8077\n",
      "\n",
      "micro avg       1.00      1.00      1.00     22590\n",
      "macro avg       1.00      1.00      1.00     22590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels = convert2label(preds2,idx2tag)\n",
    "test_labels = convert2label(preds2,idx2tag)\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
