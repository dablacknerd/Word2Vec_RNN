{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten, Embedding\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDINGS_LEN= 300\n"
     ]
    }
   ],
   "source": [
    "word2vec_embedding_len = len(nlp.vocab['apple'].vector)\n",
    "print(\"EMBEDDINGS_LEN=\", word2vec_embedding_len )  # 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADLINE</th>\n",
       "      <th>IS_SARCASTIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            HEADLINE  IS_SARCASTIC\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(),'sarcasm_headline_dataset.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['HEADLINE'].values.tolist()\n",
    "labels = df['IS_SARCASTIC'].values.tolist()\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "max_words_feature_space = len(word_index) + 1\n",
    "max_seq_len = max([len(headline) for headline in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences, maxlen=max_seq_len)\n",
    "y = np.asarray(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_embedding_matrix = np.zeros((max_words_feature_space, word2vec_embedding_len))\n",
    "for word, idx in word_index.items():\n",
    "    try:\n",
    "        embedding = nlp.vocab[word].vector\n",
    "        my_embedding_matrix[idx] = embedding\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_filename = os.path.join(os.getcwd(),'models','sarcasm','word2vec_model2_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "\n",
    "plateau_callback =ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=2)\n",
    "modelcheckpoint_callback = ModelCheckpoint(filepath=model1_filename,monitor='val_loss',save_best_only=True)\n",
    "earlystop_callback = EarlyStopping(monitor='val_loss',patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 254, 300)          8897100   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 9,618,601\n",
      "Trainable params: 721,501\n",
      "Non-trainable params: 8,897,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_words_feature_space,\n",
    "                     word2vec_embedding_len,\n",
    "                     weights=[my_embedding_matrix],\n",
    "                     input_length=max_seq_len,\n",
    "                     trainable=False))\n",
    "model1.add(LSTM(300,return_sequences=False))\n",
    "model1.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17093 samples, validate on 4274 samples\n",
      "Epoch 1/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.6542 - acc: 0.6680 - val_loss: 0.5847 - val_acc: 0.7022\n",
      "Epoch 2/30\n",
      "17093/17093 [==============================] - 251s - loss: 0.4959 - acc: 0.7756 - val_loss: 0.3872 - val_acc: 0.8250\n",
      "Epoch 3/30\n",
      "17093/17093 [==============================] - 251s - loss: 0.4331 - acc: 0.8034 - val_loss: 0.3926 - val_acc: 0.8226\n",
      "Epoch 4/30\n",
      "17093/17093 [==============================] - 251s - loss: 0.3810 - acc: 0.8312 - val_loss: 0.3669 - val_acc: 0.8329\n",
      "Epoch 5/30\n",
      "17093/17093 [==============================] - 252s - loss: 0.3217 - acc: 0.8602 - val_loss: 0.3298 - val_acc: 0.8512\n",
      "Epoch 6/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.2839 - acc: 0.8779 - val_loss: 0.3104 - val_acc: 0.8652\n",
      "Epoch 7/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.2804 - acc: 0.8883 - val_loss: 0.3196 - val_acc: 0.8617\n",
      "Epoch 8/30\n",
      "17093/17093 [==============================] - 252s - loss: 0.2234 - acc: 0.9056 - val_loss: 0.3036 - val_acc: 0.8687\n",
      "Epoch 9/30\n",
      "17093/17093 [==============================] - 252s - loss: 0.3834 - acc: 0.8398 - val_loss: 0.3442 - val_acc: 0.8465\n",
      "Epoch 10/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.2615 - acc: 0.8984 - val_loss: 0.3177 - val_acc: 0.8701\n",
      "Epoch 11/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.1823 - acc: 0.9278 - val_loss: 0.3183 - val_acc: 0.8741\n",
      "Epoch 12/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.1242 - acc: 0.9546 - val_loss: 0.3275 - val_acc: 0.8758\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_train, y_train, \n",
    "                      epochs=30, batch_size=256,\n",
    "                      verbose=1,callbacks=[plateau_callback,modelcheckpoint_callback,earlystop_callback],\n",
    "                      validation_data=(X_val, y_val)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5342/5342 [==============================] - 46s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32871628757140825, 0.8732684388092866]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 254, 300)          8897100   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               45150     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 9,663,601\n",
      "Trainable params: 766,501\n",
      "Non-trainable params: 8,897,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1_5 = Sequential()\n",
    "model1_5.add(Embedding(max_words_feature_space,\n",
    "                     word2vec_embedding_len,\n",
    "                     weights=[my_embedding_matrix],\n",
    "                     input_length=max_seq_len,\n",
    "                     trainable=False))\n",
    "model1_5.add(LSTM(300,return_sequences=False))\n",
    "model1_5.add(Dense(units=150, activation='relu'))\n",
    "model1_5.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model1_5.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
    "print(model1_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17093 samples, validate on 4274 samples\n",
      "Epoch 1/30\n",
      "17093/17093 [==============================] - 254s - loss: 0.6049 - acc: 0.7150 - val_loss: 0.6490 - val_acc: 0.5849\n",
      "Epoch 2/30\n",
      "17093/17093 [==============================] - 252s - loss: 0.6046 - acc: 0.6835 - val_loss: 0.6088 - val_acc: 0.6549\n",
      "Epoch 3/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.4971 - acc: 0.7858 - val_loss: 0.3941 - val_acc: 0.8205\n",
      "Epoch 4/30\n",
      "17093/17093 [==============================] - 252s - loss: 0.4996 - acc: 0.7694 - val_loss: 0.3715 - val_acc: 0.8379\n",
      "Epoch 5/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.3284 - acc: 0.8563 - val_loss: 0.3669 - val_acc: 0.8421\n",
      "Epoch 6/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.2865 - acc: 0.8759 - val_loss: 0.3197 - val_acc: 0.8577\n",
      "Epoch 7/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.2464 - acc: 0.8969 - val_loss: 0.3394 - val_acc: 0.8631\n",
      "Epoch 8/30\n",
      "17093/17093 [==============================] - 253s - loss: 0.2077 - acc: 0.9143 - val_loss: 0.3501 - val_acc: 0.8533\n",
      "Epoch 9/30\n",
      "17093/17093 [==============================] - 254s - loss: 0.1718 - acc: 0.9290 - val_loss: 0.3381 - val_acc: 0.8603\n",
      "Epoch 10/30\n",
      "17093/17093 [==============================] - 254s - loss: 0.1084 - acc: 0.9605 - val_loss: 0.3690 - val_acc: 0.8704\n"
     ]
    }
   ],
   "source": [
    "history1_5 = model1_5.fit(X_train, y_train, \n",
    "                      epochs=30, batch_size=256,\n",
    "                      verbose=1,callbacks=[plateau_callback,modelcheckpoint_callback,earlystop_callback],\n",
    "                      validation_data=(X_val, y_val)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5342/5342 [==============================] - 47s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.368838570523869, 0.8685885434604146]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 254, 300)          8897100   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 254, 300)          721200    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 10,339,801\n",
      "Trainable params: 1,442,701\n",
      "Non-trainable params: 8,897,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words_feature_space,\n",
    "                     word2vec_embedding_len,\n",
    "                     weights=[my_embedding_matrix],\n",
    "                     input_length=max_seq_len,\n",
    "                     trainable=False))\n",
    "model2.add(LSTM(300,return_sequences=True))\n",
    "model2.add(LSTM(300,return_sequences=False))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17093 samples, validate on 4274 samples\n",
      "Epoch 1/30\n",
      "17093/17093 [==============================] - 508s - loss: 0.5740 - acc: 0.7087 - val_loss: 0.4368 - val_acc: 0.8018\n",
      "Epoch 2/30\n",
      "17093/17093 [==============================] - 505s - loss: 0.4217 - acc: 0.8081 - val_loss: 0.4178 - val_acc: 0.8133\n",
      "Epoch 3/30\n",
      "17093/17093 [==============================] - 507s - loss: 0.3804 - acc: 0.8299 - val_loss: 0.3830 - val_acc: 0.8336\n",
      "Epoch 4/30\n",
      "17093/17093 [==============================] - 504s - loss: 0.3449 - acc: 0.8473 - val_loss: 0.9715 - val_acc: 0.5082\n",
      "Epoch 5/30\n",
      "17093/17093 [==============================] - 503s - loss: 0.3346 - acc: 0.8547 - val_loss: 0.3559 - val_acc: 0.8493\n",
      "Epoch 6/30\n",
      "17093/17093 [==============================] - 499s - loss: 0.2837 - acc: 0.8801 - val_loss: 0.3309 - val_acc: 0.8584\n",
      "Epoch 7/30\n",
      "17093/17093 [==============================] - 497s - loss: 0.2576 - acc: 0.8896 - val_loss: 0.3530 - val_acc: 0.8482\n",
      "Epoch 8/30\n",
      "17093/17093 [==============================] - 498s - loss: 0.2271 - acc: 0.9062 - val_loss: 0.4267 - val_acc: 0.8322\n",
      "Epoch 9/30\n",
      "17093/17093 [==============================] - 497s - loss: 0.2058 - acc: 0.9129 - val_loss: 0.3364 - val_acc: 0.8615\n",
      "Epoch 10/30\n",
      "17093/17093 [==============================] - 497s - loss: 0.1360 - acc: 0.9495 - val_loss: 0.3600 - val_acc: 0.8643\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y_train, \n",
    "                      epochs=30, batch_size=512,\n",
    "                      verbose=1,callbacks=[plateau_callback,modelcheckpoint_callback,earlystop_callback],\n",
    "                      validation_data=(X_val, y_val)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/tom/anaconda3/envs/keras_book/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2888: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 254, 300)          8897100   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 254, 300)          721200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 254, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 301       \n",
      "=================================================================\n",
      "Total params: 10,339,801\n",
      "Trainable params: 1,442,701\n",
      "Non-trainable params: 8,897,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2_1 = Sequential()\n",
    "model2_1.add(Embedding(max_words_feature_space,\n",
    "                     word2vec_embedding_len,\n",
    "                     weights=[my_embedding_matrix],\n",
    "                     input_length=max_seq_len,\n",
    "                     trainable=False))\n",
    "model2_1.add(LSTM(300,return_sequences=True))\n",
    "model2_1.add(Dropout(0.2))\n",
    "model2_1.add(LSTM(300,return_sequences=False))\n",
    "model2_1.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model2_1.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
    "print(model2_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17093 samples, validate on 4274 samples\n",
      "Epoch 1/30\n",
      "17093/17093 [==============================] - 510s - loss: 0.5712 - acc: 0.7033 - val_loss: 0.4359 - val_acc: 0.7934\n",
      "Epoch 2/30\n",
      "17093/17093 [==============================] - 4822s - loss: 0.4961 - acc: 0.7872 - val_loss: 0.4182 - val_acc: 0.8156\n",
      "Epoch 3/30\n",
      "17093/17093 [==============================] - 501s - loss: 0.3867 - acc: 0.8292 - val_loss: 0.4003 - val_acc: 0.8208\n",
      "Epoch 4/30\n",
      "17093/17093 [==============================] - 499s - loss: 0.3729 - acc: 0.8339 - val_loss: 0.3753 - val_acc: 0.8339\n",
      "Epoch 5/30\n",
      "17093/17093 [==============================] - 613s - loss: 0.3267 - acc: 0.8598 - val_loss: 0.4268 - val_acc: 0.8084\n",
      "Epoch 6/30\n",
      "17093/17093 [==============================] - 624s - loss: 0.3218 - acc: 0.8594 - val_loss: 0.3296 - val_acc: 0.8538\n",
      "Epoch 7/30\n",
      "17093/17093 [==============================] - 583s - loss: 0.2967 - acc: 0.8713 - val_loss: 0.3150 - val_acc: 0.8627\n",
      "Epoch 8/30\n",
      "17093/17093 [==============================] - 586s - loss: 0.2704 - acc: 0.8838 - val_loss: 0.3136 - val_acc: 0.8676\n",
      "Epoch 9/30\n",
      "17093/17093 [==============================] - 517s - loss: 0.2460 - acc: 0.8936 - val_loss: 0.3257 - val_acc: 0.8615\n",
      "Epoch 10/30\n",
      "17093/17093 [==============================] - 529s - loss: 0.2111 - acc: 0.9126 - val_loss: 0.3313 - val_acc: 0.8678\n",
      "Epoch 11/30\n",
      "17093/17093 [==============================] - 517s - loss: 0.1945 - acc: 0.9203 - val_loss: 0.3270 - val_acc: 0.8685\n",
      "Epoch 12/30\n",
      "17093/17093 [==============================] - 516s - loss: 0.1337 - acc: 0.9486 - val_loss: 0.3378 - val_acc: 0.8706\n"
     ]
    }
   ],
   "source": [
    "history2_1 = model2_1.fit(X_train, y_train, \n",
    "                      epochs=30, batch_size=512,\n",
    "                      verbose=1,callbacks=[plateau_callback,modelcheckpoint_callback,earlystop_callback],\n",
    "                      validation_data=(X_val, y_val)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5342/5342 [==============================] - 94s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35054774643753583, 0.8715836765479613]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
